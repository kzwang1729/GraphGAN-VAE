# -*- coding: utf-8 -*-
"""Copy of CPSC 483 Final Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/157Xq3vdu5JDftQQsQv6Uhh2CBgdMZy-K

#**GraphGAN-VAE**

A deep generative model for graph generation, employing a GAN architecture with a VAE generator to iteratively generate nodes from a starting graph seed. Both the generator (encoder + decoder) and the discriminator are implemented using GCN layers (Kipf & Welling, 2016).

We train the model on three different datasets (cora, citeseer, ENZYME) to evaluate the generated graphs using metrics proposed in GraphRNN (You et al., 2018).

**Installing Dependencies**
"""

import os
import torch
# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cu116.html
# !pip install ogb  # for datasets
# !pip install pyemd
print("Using torch", torch.__version__)

"""**Importing Datasets**"""

from torch_geometric.data import Data
from torch_geometric.datasets import Planetoid
from torch_geometric.datasets import ZINC
from torch_geometric.datasets import TUDataset

"""**Importing GNN Modules and other Python Modules**"""

from torch_geometric.nn import GCNConv
from torch.nn import Linear
from torch.nn import Transformer
import torch.optim as optim
import random
import numpy as np
from sklearn.utils import shuffle
import matplotlib.pyplot as plt

"""**Helper Functions to Construct Neighborhood Graphs Out of Nodes**

Our model builds a node with generated node features and connections to neighbors based on the other existing nodes in the graph. In order to train this model, we must isolate training inputs (neighborhoods of base nodes) from their ideal outputs (features of the base node and connectivity from it to other nodes). 

Since we use a GAN architecture, we need to provide two different forms of this data to the generator and discriminator. The generator receives the neighborhood feature matrix with original dimensions (i.e. each node has the same # of features that it did in the original data). The discriminator receives the neighborhood feature matrix with a column added (i.e. a new feature for each node representing the hidden nodes connections to each neighbor), as well as the hidden root node's features; this allows it to judge if the root node could potentially have been taken from a real graph. Both the generator and discriminator use the same adjaceny list input.

We provide parameters to help randomize node generation and respect the bounds of the inductive setting (only drawing nodes and edges from the appropriate inductive split).
"""

from collections import defaultdict, deque

## Helper function for tuple conversion to be processed by GPU
def transform_tuple_to_gpu(tup):
  new_tup = []
  for x in tup:
    new_tup.append(x.cuda())
  return tuple(new_tup)


def construct_naive_cluster(desired_base_node, features_list, edge_index, node_pool, max_depth=2):
    """
    In our model, new node features and connections are generated based on the existing node features and connectivity patterns of
    the existing graph. To obtain training data for this model in a tractable manner, we find the k-hop neighborhoods of potential root nodes
    to use as proxies for the features and connectivity of the entire graph at large, and feed these as inputs to our generator and 
    discriminator in order to predict properties about the root node that the computation graph was generated from.

    1. We want the training dataset to contain (1): a matrix of node features except the node added, (2): an adjacency matrix of that graph, 
    and (3): a feature vector of the added node and its adjacencies with the added nodes (as the desired output).

    2. One issue in creating this feature is that we need a way to embed the adjacency information of the original node.
    We can't do this in a static-sized input vector, as this would not scale to nodes of different degrees. Instead, we 
    add an additional feature to each of the original nodes (whether or not it connects to the added node)

    3. We want to parameterize constructing different neighborhoods. We always initially root ourselves at the
    original node and construct a max-depth-hop neighborhood from it.

    Args:
    - desired_base_node: the node that will be generated/classified by the GAN model
    - features_list: node features of entire dataset
    - edge_index: adjacency list of entire dataset
    - node_pool: set of nodes to consider in neighborhood for inductive setting
    - max_depth: parameter controlling the depth of the hop neighborhood

    Returns:
    - old_feature_matrix: features of the neighborhood without base node
    - new_feature_matrix: features as above + connectivity to base node
    - new_edge_index: adjacency list of neighborhood without base node
    - features of base node + connectivity to neighbors

    """

    ## Create a dictionary of neighbors of each node using the adjacency list
    neighbors = defaultdict(lambda: set() )
    for node1, node2 in zip(edge_index[0], edge_index[1]):
      if node1.item() in node_pool and node2.item() in node_pool:
        neighbors[node1.item()].add(node2.item()) 
    
    # If the root node has no neighbors, end
    if len(neighbors[desired_base_node]) == 0:
      return None
      
    # BFS to find a computation graph neighborhood
    included_nodes = set()
    q = deque()
    base = [max_depth, desired_base_node]
    q.append(base)
    while len(q) > 0:
      dist, curr = q.popleft()
      included_nodes.add(curr)
      # If we've expanded to desired depth, don't add neighbors 
      if dist == 0:
        continue
      for neighbor in neighbors[curr]:
        q.append([dist - 1, neighbor])
    
    # Since our computation graph is smaller, we must relabel nodes
    idx_mappings = {}
    for i, node in enumerate(included_nodes):
      idx_mappings[node] = i

    # We create an adjacency list using the relabelled nodes
    new_edge_index = [[], []]
    for node in included_nodes:
      for neighbor in neighbors[node]:
        if neighbor in idx_mappings and node in idx_mappings:
          new_edge_index[0].append(idx_mappings[node])
          new_edge_index[1].append(idx_mappings[neighbor])

    # We create both input and output feature matrices as described above
    # new_adjacency_vector contains connections from the generated/predicted root node to its neighbors
    # new_adjacency_vector is augmented to old_feature_matrix of the root's neighbors to create new_feature_matrix
    new_adjacency_vector = [None] * len(included_nodes)
    old_feature_matrix = [None] * len(included_nodes)
    new_feature_matrix = [None]*len(included_nodes)
    for node in included_nodes:      
      old_feature_matrix[idx_mappings[node]] = features_list[node].tolist()
      new_feature_matrix[idx_mappings[node]] = features_list[node].tolist() + [1 if node in neighbors[desired_base_node] else 0]
      new_adjacency_vector[idx_mappings[node]] = 1 if node in neighbors[desired_base_node] else 0
    new_adjacency_vector = torch.tensor(new_adjacency_vector)
    old_feature_matrix = torch.tensor(old_feature_matrix)
    new_feature_matrix = torch.tensor(new_feature_matrix)
    new_edge_index = torch.tensor(new_edge_index)
    return old_feature_matrix, new_feature_matrix, new_edge_index, features_list[desired_base_node][None, :], new_adjacency_vector[None, :]


def construct_cluster_dataset(data_nodes, data_edge_index, allowed_nodes, pct_of_nodes_utilized, max_neighborhood_depth):
  """
  Constructs an entire training dataset by iterating over different possible bases nodes that might be generated/classified as examples. 
  Args:
  - data_nodes: feature list of dataset
  - data_edge_index: adjacency list of entire dataset
  - allowed_nodes: the set of possible base nodes determined by the training split
  - pct_of_nodes_utilized: the fraction of possible nodes utilized as based nodes to construct dataset
  - max_neighborhood_depth: depth of the hop neighborhood

  Returns:
  - Dataset consisting of tuples of the form returned by the function above
  """
  new_dataset = []
  allowed_nodes = list(allowed_nodes)
  # Iterate through every node we have access to in the dataset split at a stepsize set by the utilization %.
  for node in range(0, len(allowed_nodes), int(1/pct_of_nodes_utilized)):
    new_cluster = construct_naive_cluster(allowed_nodes[node], data_nodes, data_edge_index, set(allowed_nodes), max_neighborhood_depth)
    if new_cluster is not None:
      new_dataset.append(transform_tuple_to_gpu(new_cluster))
  return new_dataset

"""**Helper Functions to Load Datasets**

This task requires an inductive training setting, so we include utilities to completely and randomly segment nodes into train, validate, test groups. These utilities simply yield sets of valid indices for each setting so as to facilitate neighborhood construction on valid edges.
"""

def randomly_create_dataset_training_split(iterable_dataset, p_train, p_val, p_test):
  """
  Split the data into train, val and test sets. We use a seed to allow for reproducibility.
  """
  points = np.arange(0,len(iterable_dataset)+1)
  points = shuffle(points, random_state=42)
  train = points[0:int(np.ceil(p_train*(len(points))))]
  test = points[int(np.ceil(p_train*(len(points)))):int(np.ceil((p_train+p_test)*(len(points))))]
  val = points[int(np.ceil((p_train+p_test)*(len(points)))):]
  return (train, val, test)


def load_dataset(name='cora', train_split=.33, val_split=.33, test_split=.33, pct_of_nodes_utilized_in_splits=.5, max_neighborhood_depth=3):
  """
  Loads the dataset used for benchmarking, and creates train/val/test splits for further dataset generation for training.
  """

  ## Datasets below contains one graph to iterate over
  if name == 'cora':
    dataset = Planetoid('tmp/cora', 'cora')
    node_data = dataset[0].x 
    train_nodes, val_nodes, test_nodes = randomly_create_dataset_training_split(node_data, train_split, val_split, test_split)
    cluster_loader = lambda node_grouping: construct_cluster_dataset(node_data, dataset[0].edge_index, node_grouping, pct_of_nodes_utilized_in_splits, max_neighborhood_depth) 
    return cluster_loader(train_nodes), cluster_loader(val_nodes), cluster_loader(test_nodes), node_data.shape[1]
 
  elif name == 'citeseer':
    dataset = Planetoid('tmp/citeseer', 'citeseer')
    node_data = dataset[0].x 
    train_nodes, val_nodes, test_nodes = randomly_create_dataset_training_split(node_data, train_split, val_split, test_split)
    cluster_loader = lambda node_grouping: construct_cluster_dataset(node_data, dataset[0].edge_index, node_grouping, pct_of_nodes_utilized_in_splits, max_neighborhood_depth) 
    return cluster_loader(train_nodes), cluster_loader(val_nodes), cluster_loader(test_nodes), node_data.shape[1]
  
  ## Datasets below contain multiple graphs to iterate over in creating our training set
  elif name == 'enzyme':
    dataset = TUDataset('tmp/enzyme', 'ENZYMES')
    train_set = []
    val_set = []
    test_set = []

    train_end = int(train_split*len(dataset))
    val_end = train_end + int(test_split*len(dataset))

    for i in range(0, train_end, int(1/pct_of_nodes_utilized_in_splits)):
      grouping = set(range(0, len(dataset[i].x)))
      train_set += construct_cluster_dataset(dataset[i].x, dataset[i].edge_index, grouping, 1, max_neighborhood_depth) 
    for i in range(train_end, val_end, int(1/pct_of_nodes_utilized_in_splits)):
      grouping = set(range(0, len(dataset[i].x)))
      val_set += construct_cluster_dataset(dataset[i].x, dataset[i].edge_index, grouping, 1, max_neighborhood_depth) 
    for i in range(val_end, len(dataset), int(1/pct_of_nodes_utilized_in_splits)):
      grouping = set(range(0, len(dataset[i].x)))
      test_set += construct_cluster_dataset(dataset[i].x, dataset[i].edge_index, grouping, 1, max_neighborhood_depth)

    return train_set, val_set, test_set, dataset[0].x.shape[1]

  elif name == 'zinc':
    dataset = ZINC('tmp/zinc')
    train_set = []
    val_set = []
    test_set = []

    train_end = int(train_split*len(dataset))
    val_end = train_end + int(test_split*len(dataset))

    for i in range(0, train_end, int(1/pct_of_nodes_utilized_in_splits)):
      grouping = set(range(0, len(dataset[i].x)))
      train_set += construct_cluster_dataset(dataset[i].x, dataset[i].edge_index, grouping, 1, max_neighborhood_depth) 
    for i in range(train_end, val_end, int(1/pct_of_nodes_utilized_in_splits)):
      grouping = set(range(0, len(dataset[i].x)))
      val_set += construct_cluster_dataset(dataset[i].x, dataset[i].edge_index, grouping, 1, max_neighborhood_depth) 
    for i in range(val_end, len(dataset), int(1/pct_of_nodes_utilized_in_splits)):
      grouping = set(range(0, len(dataset[i].x)))
      test_set += construct_cluster_dataset(dataset[i].x, dataset[i].edge_index, grouping, 1, max_neighborhood_depth) 

    return train_set, val_set, test_set, dataset[0].x.shape[1]

"""**Defining Mathematical Utilities**"""

def soft_round(x, alpha=torch.tensor(4)):
        """Differentiable approximation to `round`.

        Larger alphas correspond to closer approximations of the round function.
        If alpha is close to zero, this function reduces to the identity.

        This is described in Sec. 4.1. in the paper
        > "Universally Quantized Neural Compression"<br />
        > Eirikur Agustsson & Lucas Theis<br />
        """
        m = .5
        r = x - m
        z = torch.tanh(alpha / 2.) * 2.
        y = m + torch.tanh(alpha * r) / z

        return y

def uncertainty_penalization(x, multiplier):
  return torch.unsqueeze(torch.mean(multiplier*(1 - 4*torch.pow(x-.5, 2)), dim=0), -1)

def colinearity_penalization(x, multiplier):
  return multiplier*(.5 - torch.var(x))

def extreme_sparsity_penalization(x, multiplier):
  return multiplier * (1 - torch.max(x) + torch.min(x))

"""**Defining the Generator Model**

In order to define the generator module, we must define the encoder and a decoder. We use GCNs for both.
"""

class GeneratorGCN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, latent_space_size, sparsity_adjustment=.05):
        super().__init__()

        # Define constants.
        self.latent_space_size = latent_space_size

        # Define the encoder layers.
        self.encoder_conv1 = GCNConv(in_channels, hidden_channels, normalize=True)
        self.encoder_conv_means = GCNConv(hidden_channels, latent_space_size, normalize=True)
        self.encoder_conv_variances = GCNConv(hidden_channels, latent_space_size, normalize=True)

        # Define the embedding decoder layers.
        self.decoder_conv1 = GCNConv(latent_space_size, in_channels, normalize=True)
        self.decoder_conv2 = GCNConv(in_channels, in_channels, normalize=True)
        self.decoder_conv3 = GCNConv(1, hidden_channels, normalize=True)
        self.decoder_conv4 = GCNConv(hidden_channels, 1, normalize=True)
        self.decoder_linear1 = Linear(in_channels, in_channels)
        self.decoder_linear2 = Linear(in_channels, in_channels)
        self.sparsity_adjustment = sparsity_adjustment

        # Define shared layers
        self.relu = torch.nn.ReLU()

    def encoder(self, node_features, edge_index):
        # Encodes our data into a latent dimension from which we can sample.
        output = self.encoder_conv1(node_features, edge_index)
        output = self.relu(output)
        means = self.encoder_conv_means(output, edge_index)
        variances = self.encoder_conv_variances(output, edge_index)
        return means, variances
    
    def sample_from_latent(self, means, log_variances):
        # Samples from the latent space by utilizing reparameterization trick. 
        variances = torch.exp(log_variances)
        epsilon = torch.randn_like(variances)
        return means + variances * epsilon

    def decoder(self, latent_samples, node_features, edge_index):
        transformed_latent_samples = self.decoder_conv1(latent_samples, edge_index)
        # Sum the over transformed latent space to generate node features, after funnelling through a linear layer.
        new_node = self.relu(self.decoder_linear1(torch.sum(transformed_latent_samples, dim=0)[None, :]))

        # Run it through another linear layer to get our adjacency encodings. We'll could add noise via the latent samples so as not to collapse to identical adjacency embeddings.
        adjacency_encoded_new_node = self.decoder_linear2(new_node) #+ torch.mean(transformed_latent_samples, dim=0)[None, :]

        # Run a graph convolution on the original node features, matmul with the new node, get nx1 encodings of adjacency.
        # We can use a smart matrix multiply ONLY if n > 2 in the graph, as if we use a graph convolution with two nodes they will have the same embedding.
        if len(node_features) > 2:
          node_features = self.decoder_conv2(node_features, edge_index)
        new_adjacency_vector = soft_round(torch.sigmoid(node_features.matmul(adjacency_encoded_new_node.t() + self.sparsity_adjustment)))

        # Inject the adjacency vector as a column into the node feature graph as a new feature
        new_cluster_representation = torch.cat((node_features, new_adjacency_vector), dim=1)
        return new_node, new_adjacency_vector, new_cluster_representation

    def forward(self, node_features, edge_index):
        ## The generator as a whole combines the encoder, latent space sampling and the decoder.
        means, variances = self.encoder(node_features, edge_index)
        latent_sample = self.sample_from_latent(means, variances)
        new_node, new_adjacency_vector, new_cluster = self.decoder(latent_sample, node_features, edge_index)
        return new_node, new_adjacency_vector, new_cluster, means, variances

"""**Defining the Discriminator Model**

The discriminator is a simple GNN classifier, using two GCN layers to classify through an intermediary node embedding space.
"""

class DiscriminatorGCN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels=10):
        super().__init__()

        # Define the encoder layers.
        self.conv1 = GCNConv(in_channels, hidden_channels, normalize=True)
        self.conv2 = GCNConv(hidden_channels, in_channels-1, normalize=True)
        self.linear1 = Linear(in_features=in_channels-1, out_features=in_channels-1)
        self.linear2 = Linear(in_features=in_channels-1, out_features=in_channels-1)
        # Define shared layers
        self.relu = torch.nn.ReLU()
        self.sigmoid = torch.nn.Sigmoid()

    
    def forward(self, node_features, edge_index, new_potential_node):
        """
        Forward pass determines the probability of the node being generated or 
        real. Note that the alleged adjacency between the new potential node and 
        the current nodes has been added as a last feature to every node (values close to
        1 meaning the new node is adjacent to the provided nodes, values close to 0 meaning
        that the new node is not adjacent).
        """
        output = self.conv1(node_features, edge_index)
        output = self.relu(output)
        output = self.linear1(torch.sum(self.conv2(output, edge_index), dim=0)[None, :])
        
        # Vector multiply the new node into the current node for discrimination
        output = torch.sigmoid(output.matmul(self.linear2(new_potential_node).t()))
        
        return output.view(-1)

"""**Define our Train and Test Functions**"""

def train(batch, generator, discriminator, optim_gen, optim_discrim, lossfn_gen1, lossfn_gen2, lossfn_gen3, discount_rate, lossfn_discrim, internal_epochs=1): 
  # Train the Discriminator on stuff.
  discriminator.train()
  generator.eval()
  optim_discrim.zero_grad()
  positive_discrim_loss = 0
  negative_discrim_loss = 0

  ## Loop over epochs
  for i in range(0, internal_epochs):
    ## Loop over each potential training set of root node + neighbor
    for elem in batch:
      # Unpack the batch element
      old_feature_matrix, new_feature_matrix, edge_index, real_node, real_adjacency_vector = elem
      # Run the generator on the neighbors features and edge index
      fake_node, new_gen_adj_vector, fake_cluster, means, variances = generator(old_feature_matrix, edge_index)

      # Get a positive sample (real node)
      discriminator_prediction_positive = discriminator(new_feature_matrix, edge_index, real_node)
      positive_discrim_loss += lossfn_discrim(discriminator_prediction_positive, torch.tensor([1]).float().cuda())
      ## Get a negative sample (fake node)
      discriminator_prediction_negative = discriminator(fake_cluster, edge_index, fake_node)
      negative_discrim_loss += lossfn_discrim(discriminator_prediction_negative, torch.tensor([0]).float().cuda())
  
  ## Backprop loss every epoch
  total_discrim_loss = positive_discrim_loss + negative_discrim_loss
  total_discrim_loss.backward()
  optim_discrim.step()

  # Train the Generator
  generator.train()
  discriminator.eval()
  optim_gen.zero_grad()
  generator_loss = 0

  for i in range(0, internal_epochs):
    for elem in batch:
      # Unpack the batch element
      old_feature_matrix, new_feature_matrix, edge_index, real_node, real_adjacency_vector = elem
      # Run the generator on the neighbor features and edge index
      fake_node, new_gen_adj_vector, fake_cluster, means, variances = generator(old_feature_matrix, edge_index)
      ## Calculate generator loss according to function as proposed in paper
      discriminator_prediction = discriminator(fake_cluster, edge_index, fake_node)
      generator_loss += lossfn_gen1(discriminator_prediction, torch.tensor([1]).float().cuda()) + lossfn_gen2(means, variances) + \
          discount_rate * (lossfn_gen3(new_gen_adj_vector, real_adjacency_vector.t().float()) + lossfn_gen3(fake_node, real_node.float()) + \
                         + torch.squeeze(colinearity_penalization(new_gen_adj_vector, 1))  +
                         torch.squeeze(extreme_sparsity_penalization(new_gen_adj_vector, 3)))
  generator_loss.backward()
  optim_gen.step()
  return total_discrim_loss / len(batch)*internal_epochs, generator_loss / len(batch)*internal_epochs, positive_discrim_loss, negative_discrim_loss

def test(batch, generator, discriminator):
  generator.eval()
  discriminator.eval()
  # Calculate accuracy over current batch for correctly identifying reals; discriminator efficiency.
  real_preds = [torch.round(discriminator(data[1], data[2], data[3])) for data in batch]
  ## We want high accuracy on reals
  discriminator_accuracy_on_reals = sum(real_preds) / len(real_preds)
  generated_samples = [generator(data[0], data[2]) for data in batch]
  ## We want 50% accuracy on fake predictions (indistinguishable from reals)
  fake_preds = [1 - torch.round(discriminator(fakes[2], data[2], fakes[0])) for data, fakes in zip(batch, generated_samples)]
  discriminator_accuracy_on_generated = sum(fake_preds) / len(real_preds)
  return discriminator_accuracy_on_reals.item(), discriminator_accuracy_on_generated.item()

"""**General Training Loop**

Now, we train the GAN-VAE architecture over 100 epochs. We first define the model hyperparameters, loss functions and optimizers.
"""

def general_train_loop(dataset_name, epochs = 100, latent_space_dim=5, gen_discount_rate=0.999, train_split=0.6, val_split=0.2, test_split=0.2, learning_rate=1e-4, test_step=5):
  
  ## Read the dataset
  train_data, val_data, test_data, node_feature_len = load_dataset(dataset_name, train_split, val_split, test_split, 1, 3)
  
  ## Define the model hyperparameters, loss functions and optimizer.
  discriminatorGCN = DiscriminatorGCN(node_feature_len+1, 50).cuda()
  generatorGCN = GeneratorGCN(node_feature_len, 50, latent_space_dim, 0).cuda()
  discriminator_optimizer = optim.Adam(discriminatorGCN.parameters(), lr=learning_rate)
  generator_optimizer = optim.Adam(generatorGCN.parameters(), lr=learning_rate)
  discriminator_loss_fn = torch.nn.BCELoss()
  generator_reconstructive_loss = torch.nn.BCELoss()
  generator_discounted_reconstructive_loss = torch.nn.MSELoss()
  generator_loss_discount_rate = gen_discount_rate
  # Kullback-Leibler Divergence loss
  generator_kld_loss = lambda mu, sigma: -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())
    
  # Global training loop for the model
  total_real_accuracy = 0
  total_fake_accuracy = 0
  base_discount_rate = generator_loss_discount_rate
  real_accuracies = []
  fake_accuracies = []
  discrim_loss = []
  gene_loss = []

  for epoch in range(1, epochs + 1):
    # Train the model.
    discriminator_loss, generator_loss, _, _ = train(train_data, generatorGCN, discriminatorGCN, generator_optimizer, discriminator_optimizer, generator_reconstructive_loss, generator_kld_loss, generator_discounted_reconstructive_loss, base_discount_rate, discriminator_loss_fn)
    base_discount_rate *= base_discount_rate
    discrim_loss.append(discriminator_loss.item())
    gene_loss.append(generator_loss.item())

    # Update test statistics
    real_accuracy, fake_accuracy = test(val_data, generatorGCN, discriminatorGCN)
    total_real_accuracy += real_accuracy
    total_fake_accuracy += fake_accuracy
    real_accuracies.append(real_accuracy)
    fake_accuracies.append(fake_accuracy)

    # Print statistics
    print(f'Train Epoch: {epoch:03d}, Discriminator Loss: {discriminator_loss:.004f}, Generator Loss: {generator_loss:.004f}')
    if epoch % test_step == 0:
      printed_real_accuracy = real_accuracy
      printed_fake_accuracy = fake_accuracy
      print(f'Test Epoch: {epoch:03d}, Accuracy on Reals: {printed_real_accuracy:.4f}, Accuracy on Fakes: {printed_fake_accuracy:.4f}')
      total_real_accuracy = 0
      total_fake_accuracy = 0
      torch.save(generatorGCN, "/content/drive/MyDrive/generatorGCN_" + dataset_name + "_" + str(epoch))
      torch.save(discriminatorGCN, "/content/drive/MyDrive/discriminatorGCN_" + dataset_name + "_" + str(epoch))

  ## Plot loss functions and accuracy over epochs
  plt.plot(range(1, epochs+1), discrim_loss)
  plt.title('Discriminator Loss vs Epoch')
  plt.ylabel('Discriminator Loss')
  plt.xlabel('Epoch')
  plt.savefig(dataset_name+"-discrim-loss")
  plt.show()

  plt.plot(range(1, epochs+1), gene_loss)
  plt.title('Generator Loss vs Epoch')
  plt.ylabel('Generator Loss')
  plt.xlabel('Epoch')
  plt.savefig(dataset_name+"-gen-loss")
  plt.show()

  plt.plot(range(1, epochs+1), real_accuracies)
  plt.title('Real Accuracy vs Epoch')
  plt.ylabel('Real Accuracy')
  plt.xlabel('Epoch')
  plt.savefig(dataset_name+"-real-acc")
  plt.show()

  plt.plot(range(1, epochs+1), fake_accuracies)
  plt.title('Fake Accuracy vs Epoch')
  plt.ylabel('Fake Accuracy')
  plt.xlabel('Epoch')
  plt.savefig(dataset_name+"-fake-acc")
  plt.show()

  return generatorGCN, discriminatorGCN

# from google.colab import drive
# drive.mount('/content/drive')

"""#Generating Graphs

We now use our node feature + connection generator model and write functions to apply it iteratively to allow for graph generation from a small graph seed.

"""

## Generates a true subgraph of the original dataset of a small enough size to allow for EMD, MMD comparisons, using a large-hop neighborhood
## of the root node used to generate the graph.
def generate_neighborhood_subgraph(base_node, features_list, edge_index, max_depth=5):
  """
  Similar to the neighborhood graph determination function right on top, except we only need to return the subgraph
  of the dataset containing the k-hop computation graph. This serves as the 'ground truth' that we test our generated
  graphs against.
  """
  neighbors = defaultdict(lambda: set())
  for node1, node2 in zip(edge_index[0], edge_index[1]):
    neighbors[node1.item()].add(node2.item()) 
  included_nodes = set()
  # BFS to find a computation graph neighborhood.
  q = deque()
  base = [max_depth, base_node]
  q.append(base)
  while len(q) > 0:
    dist, curr = q.popleft()
    included_nodes.add(curr)
    # If we've expanded to desired depth, don't add neighbors 
    if dist == 0:
      continue
    for neighbor in neighbors[curr]:
      q.append([dist - 1, neighbor])
  # Remap indices
  idx_mappings = {}
  for i, node in enumerate(included_nodes):
    idx_mappings[node] = i

  # Create an adjacency matrix.
  edge = [[], []]
  for node in included_nodes:
    for neighbor in neighbors[node]:
      if neighbor in idx_mappings and node in idx_mappings:
        edge[0].append(idx_mappings[node])
        edge[1].append(idx_mappings[neighbor])
  edge = torch.tensor(edge)
  
  feat = [None]*len(included_nodes)
  for node in included_nodes:
    feat[idx_mappings[node]] = features_list[node].tolist()
  feat = torch.tensor(feat)
  return feat, edge

def generate_edges(node_index, adjacency_vector):
  """
  Converts an adjacency vector outputted by the generator into an 
  adjacency list to append to the new graph.
  """
  num_edges = torch.where(adjacency_vector[:,0]>0.5)[0].size(dim=0)
  adj_vec = torch.zeros((2, num_edges), dtype=torch.int64).cuda()
  adj_vec[0] = node_index
  adj_vec[1] = torch.where(adjacency_vector[:,0]>0.5)[0]
  return adj_vec

def generate_graph(generator, discriminator, num_nodes, test_data, root_node=None, max_seed_size=10):
  """
  We construct a two-hop neighborhood seed of limited size. Then, we incrementally
  generate nodes and corresponding edges to generate incrementally bigger graphs,
  until we reach the target size (determined by num_nodes).
  """
  generator.eval()
  discriminator.eval()
  ## Generate a root node that allows for a small enough seed
  if root_node is None:
    seed = None
    while seed is None or seed.shape[0] > max_seed_size:
      root_node = torch.randint(len(test_data), (1,))
      seed = test_data[root_node][0]

  ## Iteratively add generated nodes to graphs
  old_features = test_data[root_node][0]
  old_adjacency = test_data[root_node][2].type(torch.int64)
  node_idx = len(old_features)
  for i in range(num_nodes-node_idx):
    new_feature, new_adjacency, _, _, _ = generator(old_features, old_adjacency)
    old_features = torch.vstack((old_features, new_feature))
    old_adjacency = torch.hstack((old_adjacency, generate_edges(node_idx + i, new_adjacency)))
  return old_features, old_adjacency


def generate_benchmark(node_data, edge_data, test_nodes, test_data, neighborhood_depth, local_task=False, max_seed_size=10, inductive_break=None):
  """
  Generates the ground truth subgraph of the dataset for comparison. If the graph generation is meant for local purposes,
  e.g. to generate neighborhoods around a particular locus, then the root node of our benchmark should be kept the same as 
  the root of the generator.
  """
  ## To test local tasks, we use the same root node as the generator, and therefore require that the seed the generator
  ## will produce is small.
  
  if local_task:
    seed = None
    while seed is None or seed.shape[0] > max_seed_size:
      root = test_nodes[torch.randint(len(test_data), (1,))]
      seed = test_data[root][0]
  else:
    ## If not, we generate the root node randomly.
    root = torch.randint(len(test_data), (1,))
  if inductive_break is None:
    return generate_neighborhood_subgraph(root.item(), node_data, edge_data, max_depth=neighborhood_depth), root
  else:
    return generate_neighborhood_subgraph(root.item(), node_data[torch.searchsorted(inductive_break, root)].x, edge_data[torch.searchsorted(inductive_break, root)].edge_index, max_depth=neighborhood_depth), root

def recall_dataset(name, train_split, val_split, test_split, seed_hop=2):
  if name == 'cora' or 'citeseer':
    dataset = Planetoid('tmp/%s' % name, name)
    node_data = dataset[0].x 
    edge_data = dataset[0].edge_index
    _, _, test_nodes = randomly_create_dataset_training_split(node_data, train_split, val_split, test_split)
    ## We can change this parameter depending on the hop neighborhood to consider
    test_data = construct_cluster_dataset(node_data, edge_data, test_nodes, 1, seed_hop)
    return node_data, edge_data, test_nodes, test_data
  elif name == "enzyme":
    dataset = TUDataset('tmp/enzyme', 'ENZYMES')
    test_set = []
    train_end = int(train_split*len(dataset))
    val_end = train_end + int(test_split*len(dataset))
    breakpoints = []
    for i in range(val_end, len(dataset)):
      grouping = set(range(0, len(dataset[i].x)))
      breakpoints.append(breakpoints[-1]+len(dataset[i].x))
      test_set += construct_cluster_dataset(dataset[i].x, dataset[i].edge_index, grouping, 1, seed_hop) 
    test_nodes = list(range(breakpoints[-1]))
    return dataset, dataset, test_nodes, test_set

"""## Evaluation of GraphGAN-VAE

Here, we use metrics taken from the GraphRNN paper to evaluate the performance of our graph generation module. In specific, we compute the Earth Mover Distance for different statistics. We also combine these statistics into an overall Maximum Mean Displacement (MMD) statistic.
"""

from torch_geometric.utils import degree
import matplotlib.pyplot as plt
import pyemd
import scipy
import numpy as np
import networkx as nx

def to_graph(nodes, adj):
  graph = nx.Graph()
  graph.add_nodes_from(range(nodes.shape[0]))
  graph.add_edges_from(adj.T.tolist())
  return graph

def node_degrees(nodes,adj_mat):
  num_nodes = nodes.shape[0]
  row = adj_mat[0]
  return degree(adj_mat[0], dtype=torch.long,num_nodes = num_nodes) + degree(adj_mat[1], dtype=torch.long,num_nodes = num_nodes)

def node_clustering(nodes, adj):
  graph = nx.Graph()
  graph.add_nodes_from(range(nodes.shape[0]))
  graph.add_edges_from(adj.T.tolist())
  clus = nx.clustering(graph)
  clustering = [clus[i] for i in range(nodes.shape[0])]
  return clustering

def node_centrality(nodes, adj):
  graph = nx.Graph()
  graph.add_nodes_from(range(nodes.shape[0]))
  graph.add_edges_from(adj.T.tolist())
  clus = nx.degree_centrality(graph)
  clustering = [clus[i] for i in range(nodes.shape[0])]
  return clustering

def calc_emd(graph1, graph2, show=False):
  n1, a1 = graph1
  n2, a2 = graph2
  deg_emd = pyemd.emd_samples(node_degrees(n1.cpu(), a1.cpu()), node_degrees(n2.cpu(), a2.cpu()), bins=10)
  clu_emd = pyemd.emd_samples(node_clustering(n1, a1), node_clustering(n2, a2), bins=10)
  cen_emd = pyemd.emd_samples(node_centrality(n1, a1), node_centrality(n2, a2), bins=10)
  bin1, _, _ = plt.hist(node_degrees(n1.cpu(), a1.cpu()), label="Generated", alpha=0.5)
  bin2, _, _ = plt.hist(node_degrees(n2.cpu(), a2.cpu()), label="Neighborhood", alpha=0.5)
  plt.legend()
  if show:
    plt.title("Node Degrees")
    plt.show()
  b1, _, _ = plt.hist(node_clustering(n1, a1), label="Generated", alpha=0.5)
  b2, _, _ = plt.hist(node_clustering(n2, a2), label="Neighborhood", alpha=0.5)
  if show:
    plt.title("Clustering")
    plt.show()
  bi1, _, _ = plt.hist(node_centrality(n1, a1), label="Generated", alpha=0.5)
  bi2, _, _ = plt.hist(node_centrality(n2, a2), label="Neighborhood", alpha=0.5)
  if show:
    plt.title("Centrality")
    plt.show()
  return deg_emd, clu_emd, cen_emd, [bin1, b1, bi1], [bin2, b2, bi2]

## The code below is taken from GraphRNN github repo for MMD calculations
def disc(samples1, samples2, kernel,*args, **kwargs):
    ''' Discrepancy between 2 samples
    '''
    d = 0
    for s1 in samples1:
      for s2 in samples2:
        d += kernel(s1, s2, *args, **kwargs)
    d /= len(samples1) * len(samples2)
    return d

def gaussian_emd(x, y, sigma=1.0, distance_scaling=1.0):
    ''' Gaussian kernel with squared distance in exponential term replaced by EMD
    Args:
      x, y: 1D pmf of two distributions with the same support
      sigma: standard deviation
    '''
    support_size = max(len(x), len(y))
    d_mat = scipy.linalg.toeplitz(range(support_size)).astype(np.float)
    distance_mat = d_mat / distance_scaling

    # convert histogram values x and y to float, and make them equal len
    x = x.astype(np.float)
    y = y.astype(np.float)
    if len(x) < len(y):
        x = np.hstack((x, [0.0] * (support_size - len(x))))
    elif len(y) < len(x):
        y = np.hstack((y, [0.0] * (support_size - len(y))))

    emd = pyemd.emd(x, y, distance_mat)
    return np.exp(-emd * emd / (2 * sigma * sigma))

def compute_mmd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):
    ''' MMD between two samples
    '''
    # normalize histograms into pmf
    if is_hist:
        samples1 = [s1 / np.sum(s1) for s1 in samples1]
        samples2 = [s2 / np.sum(s2) for s2 in samples2]
    # print('===============================')
    # print('s1: ', disc(samples1, samples1, kernel, *args, **kwargs))
    # print('--------------------------')
    # print('s2: ', disc(samples2, samples2, kernel, *args, **kwargs))
    # print('--------------------------')
    # print('cross: ', disc(samples1, samples2, kernel, *args, **kwargs))
    # print('===============================')
    return disc(samples1, samples1, kernel, *args, **kwargs) + \
            disc(samples2, samples2, kernel, *args, **kwargs) - \
            2 * disc(samples1, samples2, kernel, *args, **kwargs)

"""## Graph Generation + Evaluation Pipeline

Having defined the relevant functions, we can now generate our graphs and evaluate their verisimilitude.
"""

## Load up the saved model and re-load the dataset.
## CHANGE THIS ACCORDING TO DATASET


"""## Testing the Model on Other Datasets


We can now analyze the perfomance of this model on different datasets.
"""

# general_train_loop("citeseer")

# general_train_loop("enzyme", epochs = 50, latent_space_dim=5, gen_discount_rate=0.999, train_split=0.6, val_split=0.2, test_split=0.2, learning_rate=1e-3, test_step=5)

# general_train_loop("zinc")